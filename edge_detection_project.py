# -*- coding: utf-8 -*-
"""Edge-Detection-Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MT-oCVq_GMZGbR6kzLewje6nd58DIGRI

**Requirements**
"""

# üé® Neural Edge-Art: Style Transfer with Edge-Aware GANs
# Optimized for Google Colab Pro (T4/V100/A100)

# ============================================================================
# SETUP CELL - Run this first!
# ============================================================================

# Check GPU
!nvidia-smi

# Install dependencies
!pip install -q torch torchvision opencv-python-headless gradio lpips

# Import libraries
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
import torchvision.models as models
from torchvision.utils import save_image
import cv2
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from google.colab import files
import io
import os
from pathlib import Path
import time

# Setup device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"\n{'='*60}")
print(f"üöÄ Device: {device}")
if torch.cuda.is_available():
    print(f"üéÆ GPU: {torch.cuda.get_device_name(0)}")
    print(f"üíæ Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")

    # Colab Pro GPU recommendations
    gpu_name = torch.cuda.get_device_name(0)
    if 'T4' in gpu_name:
        print(f"üìä Recommended: 512x512, 200 steps (~2 min)")
    elif 'V100' in gpu_name:
        print(f"üìä Recommended: 512x512, 300 steps (~90 sec)")
    elif 'A100' in gpu_name:
        print(f"üìä Recommended: 1024x1024, 500 steps (~2 min)")
print(f"{'='*60}\n")

# Enable optimizations for Colab
torch.backends.cudnn.benchmark = True
torch.backends.cuda.matmul.allow_tf32 = True

# ============================================================================
# MOUNT GOOGLE DRIVE (Optional - for saving results)
# ============================================================================

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# Create output directory in Drive
output_dir = '/content/drive/MyDrive/Neural_Edge_Art_Results'
os.makedirs(output_dir, exist_ok=True)
print(f"‚úÖ Results will be saved to: {output_dir}")

# ============================================================================
# EDGE DETECTION MODULE
# ============================================================================

class EdgeAwareProcessor:
    '''Multi-method edge detection optimized for Colab'''

    def __init__(self):
        self.kernels = {
            'sobel_x': np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float32),
            'sobel_y': np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=np.float32),
            'laplacian': np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]], dtype=np.float32),
            'prewitt_x': np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]], dtype=np.float32),
            'prewitt_y': np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]], dtype=np.float32),
        }

    def extract_edges(self, image, method='canny', threshold1=50, threshold2=150):
        if isinstance(image, Image.Image):
            image = np.array(image)

        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) if len(image.shape) == 3 else image

        if method == 'canny':
            edges = cv2.Canny(gray, threshold1, threshold2)
        elif method == 'sobel':
            sobel_x = cv2.filter2D(gray, -1, self.kernels['sobel_x'])
            sobel_y = cv2.filter2D(gray, -1, self.kernels['sobel_y'])
            edges = np.sqrt(sobel_x**2 + sobel_y**2)
            edges = np.clip(edges, 0, 255).astype(np.uint8)
        elif method == 'laplacian':
            edges = cv2.filter2D(gray, -1, self.kernels['laplacian'])
            edges = np.abs(edges)
            edges = np.clip(edges, 0, 255).astype(np.uint8)
        elif method == 'prewitt':
            prewitt_x = cv2.filter2D(gray, -1, self.kernels['prewitt_x'])
            prewitt_y = cv2.filter2D(gray, -1, self.kernels['prewitt_y'])
            edges = np.sqrt(prewitt_x**2 + prewitt_y**2)
            edges = np.clip(edges, 0, 255).astype(np.uint8)
        else:
            raise ValueError(f"Unknown method: {method}")

        return edges

    def edges_to_tensor(self, edges):
        edges_tensor = torch.from_numpy(edges).float() / 255.0
        edges_tensor = edges_tensor.unsqueeze(0).unsqueeze(0)
        return edges_tensor.to(device)

    def visualize_edges(self, image, methods=['canny', 'sobel', 'laplacian']):
        fig, axes = plt.subplots(1, len(methods) + 1, figsize=(15, 4))
        axes[0].imshow(image)
        axes[0].set_title('Original', fontsize=12, fontweight='bold')
        axes[0].axis('off')

        for i, method in enumerate(methods):
            edges = self.extract_edges(image, method)
            axes[i+1].imshow(edges, cmap='gray')
            axes[i+1].set_title(f'{method.capitalize()}', fontsize=12, fontweight='bold')
            axes[i+1].axis('off')

        plt.tight_layout()
        return fig

# ============================================================================
# VGG19 FEATURE EXTRACTOR (Lightweight for Colab)
# ============================================================================

class VGG19FeatureExtractor(nn.Module):
    '''VGG19 feature extraction optimized for memory efficiency'''

    def __init__(self):
        super().__init__()
        # Download VGG19 once
        vgg = models.vgg19(pretrained=True).features.eval()

        for param in vgg.parameters():
            param.requires_grad = False

        # Use fewer layers for Colab memory efficiency
        self.layer1 = vgg[:4]   # conv1_2
        self.layer2 = vgg[4:9]  # conv2_2
        self.layer3 = vgg[9:18] # conv3_4
        self.layer4 = vgg[18:27] # conv4_4

    def forward(self, x):
        feat1 = self.layer1(x)
        feat2 = self.layer2(feat1)
        feat3 = self.layer3(feat2)
        feat4 = self.layer4(feat3)
        return feat1, feat2, feat3, feat4

# ============================================================================
# LOSS FUNCTIONS
# ============================================================================

class StyleTransferLoss:
    '''Efficient loss computation for Colab'''

    def __init__(self, feature_extractor):
        self.feature_extractor = feature_extractor
        self.mse = nn.MSELoss()

    def gram_matrix(self, features):
        b, c, h, w = features.size()
        features = features.view(b, c, h * w)
        gram = torch.bmm(features, features.transpose(1, 2))
        return gram / (c * h * w)

    def content_loss(self, generated_features, content_features):
        return self.mse(generated_features, content_features)

    def style_loss(self, generated_features, style_features):
        loss = 0
        for gen_feat, style_feat in zip(generated_features, style_features):
            gen_gram = self.gram_matrix(gen_feat)
            style_gram = self.gram_matrix(style_feat)
            loss += self.mse(gen_gram, style_gram)
        return loss

    def edge_loss(self, generated_img, content_edges):
        gray = 0.299 * generated_img[:, 0] + 0.587 * generated_img[:, 1] + 0.114 * generated_img[:, 2]

        sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32).view(1, 1, 3, 3).to(device)
        sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=torch.float32).view(1, 1, 3, 3).to(device)

        gray = gray.unsqueeze(1)
        edges_x = F.conv2d(gray, sobel_x, padding=1)
        edges_y = F.conv2d(gray, sobel_y, padding=1)
        generated_edges = torch.sqrt(edges_x**2 + edges_y**2)

        generated_edges = (generated_edges - generated_edges.min()) / (generated_edges.max() - generated_edges.min() + 1e-8)

        return self.mse(generated_edges, content_edges)

    def total_loss(self, generated_img, content_img, style_img, content_edges,
                   content_weight=1.0, style_weight=1e6, edge_weight=100):

        gen_features = self.feature_extractor(generated_img)
        content_features = self.feature_extractor(content_img)[3]
        style_features = self.feature_extractor(style_img)

        c_loss = self.content_loss(gen_features[3], content_features)
        s_loss = self.style_loss(gen_features, style_features)
        e_loss = self.edge_loss(generated_img, content_edges)

        total = content_weight * c_loss + style_weight * s_loss + edge_weight * e_loss

        return total, c_loss, s_loss, e_loss

# ============================================================================
# MAIN STYLE TRANSFER ENGINE (Colab Optimized)
# ============================================================================

class NeuralEdgeArt:
    '''Complete system optimized for Colab Pro'''

    def __init__(self, image_size=512):
        self.image_size = image_size
        self.edge_processor = EdgeAwareProcessor()

        print("üîÑ Loading VGG19 model...")
        self.feature_extractor = VGG19FeatureExtractor().to(device)
        self.loss_fn = StyleTransferLoss(self.feature_extractor)
        print("‚úÖ Model loaded!")

        self.transform = transforms.Compose([
            transforms.Resize((image_size, image_size)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                               std=[0.229, 0.224, 0.225])
        ])

        self.denorm = transforms.Normalize(
            mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],
            std=[1/0.229, 1/0.224, 1/0.225]
        )

    def load_image(self, image_input):
        '''Load from file path, PIL image, or numpy array'''
        if isinstance(image_input, str):
            image = Image.open(image_input).convert('RGB')
        elif isinstance(image_input, np.ndarray):
            image = Image.fromarray(image_input).convert('RGB')
        else:
            image = image_input.convert('RGB')
        return self.transform(image).unsqueeze(0).to(device)

    def denormalize(self, tensor):
            img = tensor.squeeze(0).cpu().detach()
            img = torch.clamp(img, 0, 1)  # Just clamp to valid range
            return transforms.ToPILImage()(img)



    def style_transfer(self, content_img, style_img, edge_method='canny',
                      num_steps=300, content_weight=1.0, style_weight=1e6,
                      edge_weight=100, lr=0.01, show_progress=True):
        '''
        Perform edge-aware style transfer

        Optimized for Colab with:
        - Automatic GPU memory management
        - Progress visualization
        - Intermediate result display
        '''

        start_time = time.time()

        # Load images
        content = self.load_image(content_img)
        style = self.load_image(style_img)

        # Extract edges
        if isinstance(content_img, str):
            content_pil = Image.open(content_img).convert('RGB')
        elif isinstance(content_img, np.ndarray):
            content_pil = Image.fromarray(content_img).convert('RGB')
        else:
            content_pil = content_img

        content_resized = content_pil.resize((self.image_size, self.image_size))
        edges = self.edge_processor.extract_edges(content_resized, method=edge_method)
        edges_tensor = self.edge_processor.edges_to_tensor(edges)

        # Initialize
        generated = content.clone().requires_grad_(True)
        optimizer = torch.optim.Adam([generated], lr=lr)

        loss_history = {'total': [], 'content': [], 'style': [], 'edge': []}

        print(f"\nüé® Starting style transfer...")
        print(f"üìê Image size: {self.image_size}x{self.image_size}")
        print(f"üî¢ Steps: {num_steps}")
        print(f"‚ö° Device: {device}\n")

        # Progress tracking
        display_steps = [num_steps // 4, num_steps // 2, 3 * num_steps // 4]

        for step in range(num_steps):
            optimizer.zero_grad()

            total_loss, c_loss, s_loss, e_loss = self.loss_fn.total_loss(
                generated, content, style, edges_tensor,
                content_weight, style_weight, edge_weight
            )

            total_loss.backward()
            optimizer.step()

            with torch.no_grad():
                generated.clamp_(-2.5, 2.5)

            loss_history['total'].append(total_loss.item())
            loss_history['content'].append(c_loss.item())
            loss_history['style'].append(s_loss.item())
            loss_history['edge'].append(e_loss.item())

            # Progress display
            if show_progress and (step + 1) % 50 == 0:
                elapsed = time.time() - start_time
                eta = (elapsed / (step + 1)) * (num_steps - step - 1)
                print(f"Step [{step+1}/{num_steps}] | "
                      f"Total: {total_loss.item():.1f} | "
                      f"Elapsed: {elapsed:.1f}s | ETA: {eta:.1f}s")

            # Show intermediate results
            if show_progress and step in display_steps:
                intermediate = self.denormalize(generated)
                plt.figure(figsize=(10, 5))
                plt.subplot(1, 2, 1)
                plt.imshow(intermediate)
                plt.title(f'Step {step+1}/{num_steps}')
                plt.axis('off')
                plt.subplot(1, 2, 2)
                plt.plot(loss_history['total'])
                plt.title('Loss Curve')
                plt.xlabel('Step')
                plt.ylabel('Total Loss')
                plt.grid(True, alpha=0.3)
                plt.tight_layout()
                plt.show()

        # Final result
        result = self.denormalize(generated)

        total_time = time.time() - start_time
        print(f"\n‚úÖ Complete! Total time: {total_time:.1f} seconds")

        # Clear GPU memory
        del content, style, generated
        torch.cuda.empty_cache()

        return result, loss_history, edges

    def apply_creative_filters(self, image, edges):
        """Improved creative post‚Äëprocessing filters."""

        # Ensure proper formats
        if isinstance(image, Image.Image):
            img_array = np.array(image).astype(np.uint8)
        else:
            img_array = image.astype(np.uint8)

        # Ensure RGB
        if len(img_array.shape) == 2:
            img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)

        edges = edges.astype(np.uint8)
        filters = {}

        # 1) SKETCH ‚Äì grayscale + inverted edges (pencil‚Äësketch style)
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        inverted = 255 - gray
        blurred = cv2.GaussianBlur(inverted, (21, 21), 0)
        sketch = cv2.divide(gray, 255 - blurred, scale=256.0)
        sketch_rgb = cv2.cvtColor(sketch.astype(np.uint8), cv2.COLOR_GRAY2RGB)
        filters["Sketch"] = Image.fromarray(sketch_rgb)

        # 2) NEON GLOW ‚Äì blurred colored edges over original
        edges_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)
        edges_blur = cv2.GaussianBlur(edges_rgb, (15, 15), 0)
        # boost blue/green channels for a neon look
        neon_edges = edges_blur.astype(np.float32)
        neon_edges[:, :, 1] *= 1.3
        neon_edges[:, :, 2] *= 1.6
        neon_edges = np.clip(neon_edges, 0, 255).astype(np.uint8)
        neon = cv2.addWeighted(img_array, 0.7, neon_edges, 0.3, 0)
        filters["Neon Glow"] = Image.fromarray(neon)

        # 3) WATERCOLOR ‚Äì stacked bilateral + median blur
        watercolor = img_array.copy()
        watercolor = cv2.bilateralFilter(watercolor, 9, 75, 75)
        watercolor = cv2.bilateralFilter(watercolor, 9, 75, 75)
        watercolor = cv2.medianBlur(watercolor, 5)
        filters["Watercolor"] = Image.fromarray(watercolor)

        # 4) EDGE OVERLAY ‚Äì keep as is
        overlay = img_array.copy()
        overlay[edges > 128] = [255, 255, 255]
        filters["Edge Overlay"] = Image.fromarray(overlay)

        return filters


# ============================================================================
# HELPER FUNCTIONS FOR COLAB
# ============================================================================

def upload_image(prompt="Upload an image"):
    '''Upload image in Colab'''
    print(f"üì§ {prompt}")
    uploaded = files.upload()
    if uploaded:
        filename = list(uploaded.keys())[0]
        return filename
    return None

def display_results(content, style, result, edges, loss_history):
    '''Beautiful result display for Colab'''

    # Main comparison
    fig = plt.figure(figsize=(20, 5))

    plt.subplot(1, 4, 1)
    plt.imshow(content)
    plt.title('Content Image', fontsize=14, fontweight='bold')
    plt.axis('off')

    plt.subplot(1, 4, 2)
    plt.imshow(style)
    plt.title('Style Image', fontsize=14, fontweight='bold')
    plt.axis('off')

    plt.subplot(1, 4, 3)
    plt.imshow(edges, cmap='gray')
    plt.title('Detected Edges', fontsize=14, fontweight='bold')
    plt.axis('off')

    plt.subplot(1, 4, 4)
    plt.imshow(result)
    plt.title('‚ú® Final Result', fontsize=14, fontweight='bold', color='green')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

    # Loss curves
    fig, axes = plt.subplots(1, 2, figsize=(15, 4))

    axes[0].plot(loss_history['total'], linewidth=2, color='purple')
    axes[0].set_title('Total Loss', fontsize=12, fontweight='bold')
    axes[0].set_xlabel('Step')
    axes[0].set_ylabel('Loss')
    axes[0].grid(True, alpha=0.3)

    axes[1].plot(loss_history['content'], label='Content', alpha=0.8)
    axes[1].plot(loss_history['style'], label='Style', alpha=0.8)
    axes[1].plot(loss_history['edge'], label='Edge', alpha=0.8)
    axes[1].set_title('Component Losses', fontsize=12, fontweight='bold')
    axes[1].set_xlabel('Step')
    axes[1].set_ylabel('Loss')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

def save_result(image, filename=None, save_to_drive=True):
    '''Save result to Google Drive or download'''

    if filename is None:
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"neural_edge_art_{timestamp}.png"

    if save_to_drive:
        # Save to Google Drive
        filepath = os.path.join(output_dir, filename)
        image.save(filepath)
        print(f"‚úÖ Saved to Google Drive: {filepath}")
    else:
        # Save locally and download
        image.save(filename)
        print(f"‚úÖ Saved locally: {filename}")

    return filename

def create_comparison_grid(results_dict):
    '''Display multiple results in a grid'''
    n = len(results_dict)
    cols = min(3, n)
    rows = (n + cols - 1) // cols

    fig, axes = plt.subplots(rows, cols, figsize=(6*cols, 6*rows))
    if n == 1:
        axes = [axes]
    else:
        axes = axes.flatten()

    for idx, (name, img) in enumerate(results_dict.items()):
        axes[idx].imshow(img)
        axes[idx].set_title(name, fontsize=12, fontweight='bold')
        axes[idx].axis('off')

    # Hide empty subplots
    for idx in range(n, len(axes)):
        axes[idx].axis('off')

    plt.tight_layout()
    plt.show()

# ============================================================================
# QUICK START EXAMPLES
# ============================================================================

print("\n" + "="*60)
print("üé® NEURAL EDGE-ART - COLAB PRO VERSION")
print("="*60)
print("\n‚úÖ Setup complete! Ready to create art.\n")
print("üìö Quick Start:")
print("  1. Run the next cell to upload images")
print("  2. Or use example images from URLs")
print("  3. Adjust parameters and generate!")
print("\nüí° Recommended settings by GPU:")
print("  ‚Ä¢ T4:  image_size=512, steps=200")
print("  ‚Ä¢ V100: image_size=512, steps=300")
print("  ‚Ä¢ A100: image_size=1024, steps=500")
print("="*60 + "\n")

# ============================================================================
# EXAMPLE 1: UPLOAD & PROCESS (Interactive)
# ============================================================================


# Upload your images
print("Step 1: Upload content image")
content_file = upload_image("Content Image")

print("\nStep 2: Upload style image")
style_file = upload_image("Style Image")

if content_file and style_file:
    # Initialize (adjust image_size based on your GPU)
    art = NeuralEdgeArt(image_size=512)  # Use 256 for T4, 512 for V100, 1024 for A100

    # Process
    result, loss_history, edges = art.style_transfer(
        content_file,
        style_file,
        edge_method='canny',
        num_steps=200,  # Adjust based on GPU
        content_weight=1.0,
        style_weight=1e6,
        edge_weight=100,
        show_progress=True
    )

    # Display
    content_img = Image.open(content_file)
    style_img = Image.open(style_file)
    display_results(content_img, style_img, result, edges, loss_history)

    # Save to Google Drive
    save_result(result, save_to_drive=True)

    print("\nüé® Want to try creative filters?")
    filters = art.apply_creative_filters(result, edges)
    create_comparison_grid(filters)


# ============================================================================
# EXAMPLE 2: USE EXAMPLE IMAGES FROM URLS
# ============================================================================

# Download example images
!wget -q -O content.jpg "https://picsum.photos/800/600"
!wget -q -O style.jpg "https://picsum.photos/seed/art/800/600"

print("‚úÖ Example images downloaded")

# Process
art = NeuralEdgeArt(image_size=512)
result, loss_history, edges = art.style_transfer(
    'content.jpg',
    'style.jpg',
    num_steps=200
)

# Display
display_results(
    Image.open('content.jpg'),
    Image.open('style.jpg'),
    result,
    edges,
    loss_history
)

save_result(result)


# ============================================================================
# EXAMPLE 3: BATCH PROCESSING
# ============================================================================




# ============================================================================
# EXAMPLE 4: PARAMETER EXPLORATION
# ============================================================================


# Try different edge weights
art = NeuralEdgeArt(image_size=256)  # Smaller for speed
edge_weights = [0, 50, 100, 200, 400]
results = {}

for weight in edge_weights:
    print(f"\nTesting edge_weight = {weight}")
    result, _, _ = art.style_transfer(
        'content.jpg',
        'style.jpg',
        edge_weight=weight,
        num_steps=100,
        show_progress=False
    )
    results[f'Edge Weight {weight}'] = result

create_comparison_grid(results)


# ============================================================================
# GRADIO INTERFACE (Optional - for interactive use)
# ============================================================================


import gradio as gr

def process_gradio(content_img, style_img, edge_method, num_steps,
                   content_w, style_w, edge_w):
    art = NeuralEdgeArt(image_size=512)

    result, loss_history, edges = art.style_transfer(
        content_img, style_img,
        edge_method=edge_method.lower(),
        num_steps=int(num_steps),
        content_weight=float(content_w),
        style_weight=float(style_w),
        edge_weight=float(edge_w),
        show_progress=False
    )

    # Create loss plot
    fig, ax = plt.subplots(figsize=(8, 4))
    ax.plot(loss_history['total'], label='Total', linewidth=2)
    ax.plot(loss_history['content'], label='Content', alpha=0.7)
    ax.plot(loss_history['style'], label='Style', alpha=0.7)
    ax.plot(loss_history['edge'], label='Edge', alpha=0.7)
    ax.legend()
    ax.grid(True, alpha=0.3)

    edges_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)

    return result, Image.fromarray(edges_rgb), fig

# Create interface
iface = gr.Interface(
    fn=process_gradio,
    inputs=[
        gr.Image(type="pil", label="Content Image"),
        gr.Image(type="pil", label="Style Image"),
        gr.Dropdown(["Canny", "Sobel", "Laplacian"], value="Canny", label="Edge Method"),
        gr.Slider(50, 500, value=200, step=50, label="Steps"),
        gr.Slider(0.1, 10, value=1.0, step=0.1, label="Content Weight"),
        gr.Slider(1e5, 1e7, value=1e6, step=1e5, label="Style Weight"),
        gr.Slider(0, 500, value=100, step=10, label="Edge Weight"),
    ],
    outputs=[
        gr.Image(label="Result"),
        gr.Image(label="Edges"),
        gr.Plot(label="Loss History")
    ],
    title="üé® Neural Edge-Art",
    description="Edge-aware style transfer with GANs",
    allow_flagging="never"
)

iface.launch(share=True)


print("\n‚ú® All cells ready! Uncomment and run examples above.")

# ‚úÖ COPY-PASTE THIS AT END OF YOUR NOTEBOOK:

import gradio as gr

def generate(content, style):
    if not content or not style:
        return None, "Upload both images"

    art = NeuralEdgeArt(image_size=512)
    result, _, _ = art.style_transfer(content, style, num_steps=200, show_progress=False)
    torch.cuda.empty_cache()
    return result, "‚úÖ Done! Click ‚¨áÔ∏è to download"

gr.Interface(
    fn=generate,
    inputs=[gr.Image(type="pil", label="Content"),
           gr.Image(type="pil", label="Style")],
    outputs=[gr.Image(type="pil", label="Result"), gr.Textbox(label="Status")],
    title="üé® Neural Edge-Art"
).launch(share=True)